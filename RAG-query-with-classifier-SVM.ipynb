{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49f82f1-f42d-4606-bb37-44a797699196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.7-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.0-cp312-cp312-win_amd64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\.conda\\envs\\pytorch_cuda_gpu\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 3.9 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.1/10.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.4/10.0 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.7/10.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.8/10.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.1/10.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.0 MB 5.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.8/11.0 MB 4.4 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.0 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.2/11.0 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.0/11.0 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.7-cp312-cp312-win_amd64.whl (436 kB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pyarrow-18.0.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/25.1 MB 4.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 2.1/25.1 MB 4.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.1/25.1 MB 5.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.2/25.1 MB 5.0 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.2/25.1 MB 4.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.6/25.1 MB 4.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.3/25.1 MB 4.9 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.7/25.1 MB 4.9 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 10.0/25.1 MB 5.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.7/25.1 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.5/25.1 MB 4.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.6/25.1 MB 4.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.6/25.1 MB 4.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 14.4/25.1 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 16.0/25.1 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.8/25.1 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.8/25.1 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.9/25.1 MB 4.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.2/25.1 MB 4.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 21.2/25.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.3/25.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.3/25.1 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.4/25.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.0/44.5 MB 5.6 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 2.1/44.5 MB 4.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.4/44.5 MB 5.3 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 4.2/44.5 MB 4.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 5.2/44.5 MB 4.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 6.3/44.5 MB 4.8 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 7.3/44.5 MB 5.0 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 8.4/44.5 MB 4.8 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 9.4/44.5 MB 5.0 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 10.7/44.5 MB 5.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 11.8/44.5 MB 5.0 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 12.8/44.5 MB 5.0 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 14.2/44.5 MB 5.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 15.2/44.5 MB 5.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 16.3/44.5 MB 5.0 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 17.3/44.5 MB 5.0 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 18.6/44.5 MB 5.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 19.4/44.5 MB 5.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 20.4/44.5 MB 5.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 21.5/44.5 MB 5.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 22.5/44.5 MB 5.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 23.3/44.5 MB 5.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 24.6/44.5 MB 5.0 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 25.7/44.5 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 26.7/44.5 MB 5.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 28.3/44.5 MB 5.0 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 29.4/44.5 MB 5.0 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 30.7/44.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 31.7/44.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 32.8/44.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 33.8/44.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 34.9/44.5 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 35.9/44.5 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 37.0/44.5 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 37.7/44.5 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 39.1/44.5 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 40.1/44.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.4/44.5 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.5/44.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.5/44.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 1.3/2.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.18.0-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Installing collected packages: xxhash, tqdm, threadpoolctl, scipy, safetensors, regex, pyarrow, propcache, multidict, joblib, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, scikit-learn, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.11.7 aiosignal-1.3.1 datasets-3.1.0 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.26.2 joblib-1.4.2 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.0 pyarrow-18.0.0 regex-2024.11.6 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0 tokenizers-0.20.3 tqdm-4.67.1 transformers-4.46.3 xxhash-3.5.0 yarl-1.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.5.0 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.13.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b259cd-3cf6-4c3d-a47d-0cff682f6985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c3784865bc4e9b8cf9c3814c92a77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/9.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\.conda\\envs\\pytorch_cuda_gpu\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\datasets--HuggingFaceTB--smoltalk. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328431b0e6034c7ca8351fff3fac7993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00009.parquet:   0%|          | 0.00/223M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f35fceb061945928f81f2d24db6bdb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00001-of-00009.parquet:   0%|          | 0.00/223M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d99ffed63a41b6be6d1c86f1ba3188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00002-of-00009.parquet:   0%|          | 0.00/223M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4fed984b7c40c2942a578eeabdf6a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00003-of-00009.parquet:   0%|          | 0.00/223M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22715ac362054067b921748c224a4fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00004-of-00009.parquet:   0%|          | 0.00/224M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a307a07beb4aa88bc61a060538bcb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00005-of-00009.parquet:   0%|          | 0.00/222M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7802be12d54c368f476dd9b5cd7345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00006-of-00009.parquet:   0%|          | 0.00/223M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8dabf52bc9a42ad8d86b12681145aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00007-of-00009.parquet:   0%|          | 0.00/224M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eef05c97a874391b7178c4c3195ce7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00008-of-00009.parquet:   0%|          | 0.00/224M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8b24c781794f6ba81694c5de17df35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/105M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3f6052839c4ebeaa2f11882475f833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1043917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4739a7d7c5b4e8892b8872ed5f83072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/54948 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"Column query not in the dataset. Current columns in the dataset: ['messages', 'source']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Step 1: Load Dataset\u001b[39;00m\n\u001b[0;32m      9\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuggingFaceTB/smoltalk\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m queries \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m contexts \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieved_context\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     12\u001b[0m labels \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch_cuda_gpu\\Lib\\site-packages\\datasets\\arrow_dataset.py:2762\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2761\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(key)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch_cuda_gpu\\Lib\\site-packages\\datasets\\arrow_dataset.py:2746\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2744\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m   2745\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m-> 2746\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m   2747\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[0;32m   2748\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[0;32m   2749\u001b[0m )\n\u001b[0;32m   2750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch_cuda_gpu\\Lib\\site-packages\\datasets\\formatting\\formatting.py:590\u001b[0m, in \u001b[0;36mquery_table\u001b[1;34m(table, key, indices)\u001b[0m\n\u001b[0;32m    588\u001b[0m         _raise_bad_key_type(key)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 590\u001b[0m     _check_valid_column_key(key, table\u001b[38;5;241m.\u001b[39mcolumn_names)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    592\u001b[0m     size \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table\u001b[38;5;241m.\u001b[39mnum_rows\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch_cuda_gpu\\Lib\\site-packages\\datasets\\formatting\\formatting.py:527\u001b[0m, in \u001b[0;36m_check_valid_column_key\u001b[1;34m(key, columns)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_valid_column_key\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m, columns: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m--> 527\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column query not in the dataset. Current columns in the dataset: ['messages', 'source']\""
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "dataset = load_dataset(\"HuggingFaceTB/smoltalk\", \"all\")\n",
    "queries = dataset[\"train\"][\"query\"]\n",
    "contexts = dataset[\"train\"][\"retrieved_context\"]\n",
    "labels = dataset[\"train\"][\"label\"]\n",
    "\n",
    "# Step 2: Use TF-IDF for Retrieval\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "vectorizer.fit(contexts)\n",
    "\n",
    "retrieved_contexts = []\n",
    "for query in queries:\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarity_scores = (query_vector @ vectorizer.transform(contexts).T).toarray().flatten()\n",
    "    best_match_idx = similarity_scores.argmax()\n",
    "    retrieved_contexts.append(contexts[best_match_idx])\n",
    "\n",
    "# Step 3: Use RAG for Generated Answers\n",
    "rag_pipeline = pipeline(\"question-answering\", model=\"facebook/rag-token-base\")\n",
    "generated_answers = [\n",
    "    rag_pipeline({\"question\": query, \"context\": context})[\"answer\"]\n",
    "    for query, context in zip(queries, retrieved_contexts)\n",
    "]\n",
    "\n",
    "# Step 4: Prepare Data for SVM\n",
    "X = [\" \".join([query, context]) for query, context in zip(queries, retrieved_contexts)]\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "y = labels\n",
    "\n",
    "# Step 5: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train SVM Classifier\n",
    "svm = SVC(kernel=\"linear\", C=1.0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Evaluate SVM\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d7dc43-e9b2-4b4d-a997-3f86b137807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['messages', 'source']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"HuggingFaceTB/smoltalk\", \"all\")\n",
    "print(dataset[\"train\"].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e2bd1-d244-4658-9122-de84fa0ddb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Step 1: Load Dataset\n",
    "dataset = load_dataset(\"HuggingFaceTB/smoltalk\", \"all\")\n",
    "queries = dataset[\"train\"][\"messages\"]  # Extract queries\n",
    "contexts = dataset[\"train\"][\"source\"]  # Extract contexts\n",
    "labels = [0] * len(queries)  # Assign dummy binary labels if labels are not provided\n",
    "\n",
    "# Step 2: Use TF-IDF for Retrieval\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "vectorizer.fit(contexts)\n",
    "\n",
    "retrieved_contexts = []\n",
    "for query in queries:\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarity_scores = (query_vector @ vectorizer.transform(contexts).T).toarray().flatten()\n",
    "    best_match_idx = similarity_scores.argmax()\n",
    "    retrieved_contexts.append(contexts[best_match_idx])\n",
    "\n",
    "# Step 3: Use RAG for Generated Answers\n",
    "rag_pipeline = pipeline(\"question-answering\", model=\"facebook/rag-token-base\")\n",
    "generated_answers = [\n",
    "    rag_pipeline({\"question\": query, \"context\": context})[\"answer\"]\n",
    "    for query, context in zip(queries, retrieved_contexts)\n",
    "]\n",
    "\n",
    "# Step 4: Prepare Data for SVM\n",
    "X = [\" \".join([query, context]) for query, context in zip(queries, retrieved_contexts)]\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Step 5: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train SVM Classifier\n",
    "svm = SVC(kernel=\"linear\", C=1.0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Evaluate SVM\n",
    "y_pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f37b4a-10ef-4437-b51a-178a05785b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
